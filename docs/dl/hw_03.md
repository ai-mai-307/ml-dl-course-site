# Описание задания

Наскучил старый плейлист? Не беда. В этом задании вы реализуете и обучите на датасете Free Music Archive автоэнкодер, с помощью которого вы получите внутренние **эмбеддинги** музыкальных композиций и проверите, дают ли эти эмбеддинги лучшие рекомендации, чем уже готовое решение без применения нейронных сетей.

## Что находится в датасете

- Аудио-клипы (MP3): ~8 000 треков по 30 с, разложены по папкам fma_small/NNN/NNNNNN.mp3 (шестизначный ID = имя файла, папка — первые 3 цифры).
- Метаданные: tracks.csv (в т.ч. поля genre_top, artist), genres.csv, и пр.

## Бейзлайн

Готовый бейзлайн вы можете найти в демо блокноте №2 к Лекции №3 курса "Глубокое машинное обучение". В нем представлено базовое решение, где для каждой музыкальной композиции вычисляется вектор из "классических", "явных" признаков-характеристик аудиосигнала.

## Постановка задачи

Реализовать и обучить один или несколько автоэнкодеров, отличающиеся друг от друга видом входных данных и способом их обработки (линейные слои, одномерные или двумерные сверточные слои). Ваша цель — получить эмбеддинги, которые обеспечат лучшие рекомендации, чем у бейзлайна.

## Как проверять качество рекомендаций

У нас нет заранее "правильных" релевантных ответов, поэтому проводим прикладные эксперименты:

1. Выберете на свой вкус 5–10 треков разных жанров и исполнителей.
2. Убедитесь, что для похожих и разных композиций косинусная близость между эмбеддингами соотвтетствует действительности (для разных треков -- большое значение, для похожих треков -- маленькое значение).
3. Для каждого запроса посчитайте топ-K рекомендаций  и сравните их с теми, которые возвращает бейзлайн.

## Критерии оценивания

### Обязательные условия

- решение — в ноутбуке solution.ipynb;
- аккуратный вид блокнота: заголовки, поясняющие текстовые блоки, без мусорных ячеек и незакрытых ошибок;
- нет подозрений на недобросовестное использование LLM.

Работа с нарушением обязательных условий оценивается в "0" баллов. Комнаде дается одна попытка на внесение исправлений.

### Задача №1. Подготовка данных и torch.utils.data.Dataset

- 2 — реализован собственный Dataset, который корректно читает аудио FMA и формирует корретный вход для одного или нескольих автоэнкодера.
- 1 — реализовано с недочётами и замечаниями (например, допущена медленная операция чтения с диска)
- 0 — не реализован.

### Задача №2. Реализация автоэнкодера

- 3 — реализовано **больше одного** варианта автоэнокдера, все варианты архитектур реализована самостоятельно, код чистый и хорошо структурирован;
- 2 — реализован один вариант автоэнкодера, архитектура реализована полностью самостоятельно, код читсый и хорошо структурирован;
- 1 — использованы готовые имплементации, есть существенные замечания к реализации архитектур, логические или вычислительные ошибки.
- 0 — модель не реализована.

### Задача №3. Обучение и логирование

- 3 — успешно обучены (val reconstruction loss уменьшается) несколько вариантов автоэнкодера; результаты экспериментов со всей необходимой информацией засены в сводную таблицу, осуществлено логирование графиков в ClearML или TensorBord;
- 2 — успешно обучен один вариант автоэнкодера, результаты экспериментов со всей необходимой информацией засены в сводную таблицу, осуществлено логирование графиков в ClearML или TensorBord;
- 1 — обучение автоэнкодеров оказалось не успешным, проведено мало экспериментов, найдены логические или вычислительные ошибки.
- 0 — модели не обучены.

### Задача №4. Эксперименты с рекомендациями

- 2 — проведено подробное экспериментальное сравнение рекомендаций от бейзлайна и вашей автоэнкодерной модели на 5–10 выбранных треках с разными исполнителями/жанрами; есть прослушивание и описательные заметки; приведены простые подсчёты (сколько совпадений по артисту/жанру в топ-K); сделаны аргументированные выводы когда и почему AE выигрывает/проигрывает.
- 1 — анализ поверхностный или противоречивый.
- 0 — анализа нет.